# Классификатор женского/мужского голоса
## Постановка задачи
Изучить возможность построения бинарного классификатора звукового сигнала на женский или мужской голос. 
Оцениваемая метрика: коэффициент кореляции Метьюза. 
## Данные
Используется [dev-clean](https://www.openslr.org/resources/60/dev-clean.tar.gz) с [openslr](http://www.openslr.org/60/).
Чтобы скачать воспользуйтесь
```
curl https://www.openslr.org/resources/60/dev-clean.tar.gz --output tmp; tar -xf tmp;rm LibriTTS data; rm tmp
```
## Установка
Используется Python 3.7
Для установки необходимых зависимостей используйте
```
pip install -r requirements.txt
```
## Проделанная работа
* Проведен первичный анализ данных. Выдвинута гипотеза о необходимости работать с признаком тона.  [EDA.ipynb](https://github.com/Stasiche/female_male_classification/blob/main/EDA.ipynb)
* Проведен анализ существующих статей на данную тему, выбрана наиболее подходящая:  'Classification of Male and Female Speech Using Perceptual Features' DOI:10.1109/ICCCNT.2017.8204065. [Ссылка](https://ieeexplore.ieee.org/abstract/document/8204065). Реализованы идеи, описанные в ней [main_article.ipynb](https://github.com/Stasiche/female_male_classification/blob/main/main_article.ipynb). Результаты показались неудовлетворительными, поэтому решено было склеить фрагменты аудио в более длинные дорожки, однако результаты от этого не улучшилсь [main_article_audio_concatenation.ipynb](https://github.com/Stasiche/female_male_classification/blob/main/main_article_audio_concatenation.ipynb).
* Получив в процессе реализации идей статьи опыт, было решено попытаться улучшить результат. [main.ipynb](https://github.com/Stasiche/female_male_classification/blob/main/main.ipynb)
* Испробован подход применения глубокого машинного обучения (сверточных нейроных сетей) для решения задачи. [main_DL.ipynb](https://github.com/Stasiche/female_male_classification/blob/main/main_DL.ipynb)

## Выводы
Промежуточные итоги можно прочитать в конце каждого ноутбука, но для удобства здесь я подведу общий итог.

Лучше с точки зрения качества предсказания показало себя решение с помощью нейронных сетей. Хотя различие, как мне кажется не столь велико, чтобы жертвовать интерпретируемостью и технической простотой (не требуется GPU и прочего) решений, полученных с помощью классического машинного обучения. 

Интересно себя показало понижение размерности -- иногда было лучше без его использования, иногда с, иногда оно не имело никакого влияния.

Для наглядности, приведу таблицу с основными результатами:

| Метод             | Доля правильных ответов | F1   | Коэффициент Метьюза |
|-------------------|-------------------------|------|---------------------|
| SVM_rbf_article   | 0.54                    | 0.54 | 0.20                |
| SVM_rbf_custom    | 0.84                    | 0.84 | 0.70                |
| KNN_article       | 0.60                    | 0.62 | 0.21                |
| KNN_custom        | 0.78                    | 0.78 | 0.59                |
| RF_article_pca    | 0.60                    | 0.61 | 0.23                |
| RF_article_no_pca | 0.81                    | 0.82 | 0.64                |
| RF_custom         | 0.84                    | 0.85 | 0.69                |
| CNN               | 0.90                    | 0.89 | 0.81                |

article/custom -- классификатор над признакми из статьи/моими

SVM -- метод опорных векторов, rbf -- в качестве ядра используется Radial Basis Function.

KNN -- метод ближих соседей

RF -- случайный лес

CNN -- сверточная нейронная сеть.

Касательно решений, основанных на классическом мл -- подтвердилась важность признака о различиях высоты голоса у женщин и мужчин. Без этого признакак классификация была плохой. 

## Заметки
* Хотелось бы обратить внимание, что неиспользование классчических train-val сплитов датасета обусловенно необходимостью избежать даталиков. Поэтому приходится делить не аудиозаписи, а дикторов и потом уже выбирать дорожки, соотвествующие выбранным дикторам.
* Вместе с коэффициентом Метьюза выводится доля правильных ответов и f1-мера для бОльшей наглядности результатов.
